{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.01\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_augment.npz file which is prepared from manual analysis, which consist of \n",
    "#count of encoding samples which have be augmented\n",
    "\n",
    "data1 = np.load('/bigpool/Team3/count_augment.npz') \n",
    "\n",
    "#loading of labels, gaze and image frames and timestamps(not images)\n",
    "data2 = np.load('/bigpool/Team3/P01_10_OutputLabels_timestamp.npz')\n",
    "data3 = np.load('/bigpool/Team3/P01_10gaze30.npz')\n",
    "data4 = np.load('/bigpool/Team3/P01_10_VideoFrames_Timestamp.npz')\n",
    "daq = data1['a']\n",
    "label = data2['label']\n",
    "gaze30 = data3['inputs']\n",
    "vid = data4['frames']\n",
    "\n",
    "#code to select samples for data augmentation of required labels in a random way  \n",
    "\n",
    "(rd,cd) = daq.shape\n",
    "(rl,cl) = label.shape\n",
    "label = label[label[:,0].argsort()]\n",
    "u = np.unique(label[:,0])\n",
    "da_full = []\n",
    "for i in range(rd):\n",
    "    print(i,\"is going on\")\n",
    "    c = 0\n",
    "    for j in range(rl):\n",
    "        if np.array_equal(daq[i,(0,1,2,3,4,5,6,7,8)], label[j,(1,2,3,4,5,6,7,8,9)]):           \n",
    "            da_full.append(label[j,:])\n",
    "            c = c+1\n",
    "    print(i,\" count:\", c)\n",
    "    da_select = random.sample(da_full, daq[i,9])\n",
    "    da_full.clear()\n",
    "    if i == 0:\n",
    "        da = np.asarray(da_select)\n",
    "    else:\n",
    "        da_temp =  np.asarray(da_select)\n",
    "        da = np.vstack((da,da_temp))           \n",
    "                         \n",
    "\n",
    "            \n",
    "# taking the gaze data for augmentation of selected samples\n",
    "(rda,cda) = da.shape\n",
    "(l,m,n) = gaze30.shape\n",
    "gaze30_da = np.zeros((rda,m,n))\n",
    "e = 0\n",
    "count = 0\n",
    "da = da[da[:,0].argsort()]\n",
    "for i in range(rda):\n",
    "    print(i ,\"is done out of \",rda )    \n",
    "    for j in range(e,l):        \n",
    "        if da[i,0] == gaze30[j,0,0]:\n",
    "            count = count +1            \n",
    "            gaze30_da[i,:,:] = gaze30[j,:,:] \n",
    "            e = j\n",
    "            break     \n",
    "    \n",
    "print(\"total matched is : \",count )         \n",
    "\n",
    "\n",
    "# taking the frame numbers(along with time stamps) for augmentation of selected samples\n",
    "(rda,cda) = da.shape\n",
    "(lv,mv) = vid.shape\n",
    "vid_da = np.zeros((rda,mv))\n",
    "vid = vid[vid[:,0].argsort()]\n",
    "e = 0\n",
    "count = 0\n",
    "da = da[da[:,0].argsort()]\n",
    "for i in range(rda):\n",
    "    print(i ,\"is done out of \",rda )    \n",
    "    for j in range(e,lv):        \n",
    "        if da[i,0] == vid[j,0]:\n",
    "            count = count +1            \n",
    "            vid_da[i,:] = vid[j,:] \n",
    "            e = j\n",
    "            break     \n",
    "print(\"total to be matched: \",rda)    \n",
    "print(\"total matched is : \",count )\n",
    "\n",
    "np.savez('/bigpool/Team3/data_augment_label.npz', label_da = da)\n",
    "np.savez('/bigpool/Team3/data_augment_gaze30.npz', gaze30_da = gaze30_da)\n",
    "np.savez('/bigpool/Team3/data_augment_vid.npz', vid_da = vid_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the files data_augment_gaze30.npz contains the gaze data to be augmented\n",
    "#data_augment_vid.npz contains timestamps of frames to be augmented\n",
    "data1 = np.load(\"/bigpool/Team3/data_augment_gaze30.npz\")\n",
    "gaze_data = data1['gaze30_da']\n",
    "data2 = np.load(\"/bigpool/Team3/data_augment_vid.npz\")\n",
    "video_frames = data2['vid_da']\n",
    "\n",
    "print(gaze_data.shape,video_frames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(gaze_data.shape[0]):\n",
    "    gaze_data[i,:,1] = 1 - gaze_data[i,:,1]# Augment only gaze x and pupil x\n",
    "    gaze_data[i,:,3] = 1 - gaze_data[i,:,3]\n",
    "\n",
    "#create new hdf5 file to store Augmented Gaze data in a dataset\n",
    "with h5py.File('/bigpool/Team3/Augmented_GazeData.hdf5','a') as f:\n",
    "    gaze_dataset = f.create_dataset('Gaze', data = gaze_data)\n",
    "\n",
    "np.savez('/bigpool/Team3/Gaze_DataAugmented.npz', gaze_data = gaze_data)#save augmented gaze data in .npz file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video frames augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder name for each person's scene video\n",
    "folder_list = [\"P01_2014_05_20\",\"P02_2014_05_24\",\"P03_2014_05_26\",\"P04_2014_05_29\",\"P05_2014_05_30\",\n",
    "               \"P06_2014_05_31\",\"P07_2014_06_04\",\"P08_2014_06_07\",\"P09_2014_06_08\",\"P10_2014_06_09\"]\n",
    "timestamp_limit = [1000000, 2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000]# modified timestamps range for each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/bigpool/Team3/Augmented_Frames.hdf5','a') as f:\n",
    "    video_dataset = f.create_dataset('Video', (1,180,320,3), maxshape = (None,180,320,3))\n",
    "    timestamp_dataset = f.create_dataset('Timestamp',(1,1), maxshape = (None,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract selected frame,resize and flip it vertically.\n",
    "def frame(path):\n",
    "    \n",
    "    with h5py.File('/bigpool/Team3/Augmented_Frames.hdf5','a') as f:\n",
    "\n",
    "        vid = cv2.VideoCapture(path)\n",
    "        vid.set(1,video_frames[i,1])\n",
    "        success,image = vid.read() \n",
    "        image = cv2.resize(image, (0,0), fx=0.25, fy=0.25)  #resize the image\n",
    "        flip_image = cv2.flip(image, 1) #flip the image vertically\n",
    "        flip_image = flip_image.reshape((1,180,320,3))\n",
    "        print (\"timestamp:\",video_frames[i,0])\n",
    "        f['Video'].resize((f['Video'].shape[0] + flip_image.shape[0]), axis = 0)\n",
    "        f['Video'][-flip_image.shape[0]:] = flip_image\n",
    "        f['Timestamp'].resize((f['Timestamp'].shape[0] + 1), axis = 0)\n",
    "        f['Timestamp'][-1:] = video_frames[i,0]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp1: 1025587.0\n",
      "timestamp1: 1025588.0\n",
      "timestamp1: 1025589.0\n",
      "timestamp1: 1025590.0\n",
      "timestamp1: 1025591.0\n",
      "timestamp1: 1025592.0\n",
      "timestamp1: 1025593.0\n",
      "timestamp1: 1025594.0\n",
      "timestamp1: 1025595.0\n",
      "timestamp1: 1025596.0\n",
      "timestamp1: 1025597.0\n",
      "timestamp1: 1025598.0\n",
      "timestamp1: 1025599.0\n",
      "timestamp1: 1025600.0\n",
      "timestamp1: 1025601.0\n",
      "timestamp1: 1025602.0\n",
      "timestamp1: 1025603.0\n",
      "timestamp1: 1025604.0\n",
      "timestamp1: 1025605.0\n",
      "timestamp1: 1025606.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-71b6ed826302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimestamp_limit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mvideo_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtimestamp_limit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/bigpool/UbiComp2015/Recordings/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"/4Recording/world_Rec.mkv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-1257cc644ac5>\u001b[0m in \u001b[0;36mframe\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvideo_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#resize the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for t in range(len(timestamp_limit)):\n",
    "    with h5py.File('/bigpool/Team3/Augmented_VideoP0%s.hdf5',(t+1),'a') as f:\n",
    "        video_dataset = f.create_dataset('Video', (1,180,320,3), maxshape = (None,180,320,3))\n",
    "        timestamp_dataset = f.create_dataset('Timestamp',(1,1), maxshape = (None,1))\n",
    "    for i in range(video_frames.shape[0]):\n",
    "        if timestamp_limit[t] <= video_frames[i,0] < timestamp_limit[t] + 1000000:\n",
    "            path = os.path.join(\"/bigpool/UbiComp2015/Recordings/\" + folder_list[t] +\"/4Recording/world_Rec.mkv\")\n",
    "            frame(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading of the np file which have images of scene data \n",
    "data_v = np.load('/bigpool/Team3/P10_OneSec.npz')\n",
    "video = data_v['small_images_np']\n",
    "\n",
    "\n",
    "#file Delete_TimeStamps.npz consist of details of which samples to be deleted\n",
    "data = np.load('/bigpool/Team3/Delete_TimeStamps.npz')\n",
    "delet = data['delet']\n",
    "data1 = np.load('/bigpool/Team3/P10_VideoFrames_Timestamp.npz')\n",
    "frame = data1['frames']\n",
    "\n",
    "delet_sort = np.sort(delet)\n",
    "\n",
    "#deletion of certain image to balance the count\n",
    "video_time = frame[:,0]\n",
    "video_del = np.intersect1d(video_time, delet_sort, return_indices=True)\n",
    "video_index = video_del[1]\n",
    "frame_del_done = np.delete(frame,video_index , axis=0)\n",
    "video_del_done = np.delete(video,video_index , axis=0)\n",
    "\n",
    "#for checking the count\n",
    "print(video.shape, \"is the shape of video files before deletion\")\n",
    "print(video_del_done.shape, \"is the shape of video files after deletion\")\n",
    "print(frame.shape, \"is the shape of frames after deletion\")\n",
    "print(frame_del_done.shape, \"is the shape of frames after deletion\")\n",
    "\n",
    "np.savez('/bigpool/Team3/P10_OneSec_afterDeletion.npz', video_del_done = video_del_done)\n",
    "np.savez('/bigpool/Team3/P10_VideoFrames_Timestamp_after_del.npz', frame_del_done = frame_del_done)\n",
    "\n",
    "#this same code can be used for deletion of gaze and labels with sight modifications like changing file directory names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addition of augmented data to original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addition of augmented gaze data to the original dataset\n",
    "\n",
    "data1 = np.load('/bigpool/Team3/P01_10gaze30_afterDeletion.npz') #Original gaze data after deletion\n",
    "gaze_delete = data1['gaze_del_done']\n",
    "\n",
    "data2 = np.load('/bigpool/Team3/Gaze_DataAugmented.npz') #Augmented gaze data\n",
    "gaze_augment = data2['gaze_data']\n",
    "\n",
    "total_gaze = np.vstack((gaze_delete,gaze_augment))\n",
    "for t in range(len(timestamp_limit)):\n",
    "    gaze_person = []\n",
    "    for i in range(total_gaze.shape[0]):\n",
    "        if timestamp_limit[t] <= total_gaze[i,0,0] < timestamp_limit[t] + 1000000:\n",
    "            gaze_person.append(total_gaze[i])\n",
    "    gaze_person_np = np.asarray(gaze_person)\n",
    "    print(gaze_person_np.shape)\n",
    "    np.savez('/bigpool/Team3/OneSec/P0%s_OneSec_Gaze30_Final.npz',(t+1) gaze_person_np = gaze_person_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addition of augmented labels to the original dataset\n",
    "\n",
    "data3 = np.load('/bigpool/Team3/P01_10_OutputLabels_timestamp_afterDeletion.npz') #Original labels after deletion\n",
    "label_delete = data3['label_del_done']\n",
    "\n",
    "data4 = np.load('/bigpool/Team3/data_augment_label.npz') #Augmented frames\n",
    "label_augment = data4['label_da']\n",
    "\n",
    "total_label = np.vstack((label_delete,label_augment))\n",
    "for t in range(len(timestamp_limit)):\n",
    "label_person = []\n",
    "    for i in range(total_label.shape[0]):\n",
    "        if timestamp_limit[t] <= total_label[i,0,0] < timestamp_limit[t] + 1000000:\n",
    "            label_person.append(total_label[i])\n",
    "    label_person_np = np.asarray(label_person)\n",
    "    np.savez('/bigpool/Team3/OneSec/P0%s_OneSec_Label_Final.npz',(t+1) label_person_np = label_person_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addition of augmented frames to the original dataset\n",
    "data1= np.load('/bigpool/Team3/P03_OneSec_afterDeletion.npz')# Original frames after deletion\n",
    "input1 = data1['video_del_done']\n",
    "\n",
    "with h5py.File('/bigpool/Team3/Augmented_VideoP03.hdf5','r') as f: #Augmented frames\n",
    "    augment_data = f['Video_Frames'][:]\n",
    "    \n",
    "with h5py.File('/bigpool/Team3/Total_VideoP3.hdf5','a') as f:\n",
    "    video_dataset = f.create_dataset('Total_Video', data = input1, maxshape = (None,180,320,3))\n",
    "    f['Total_Video'].resize((f['Total_Video'].shape[0] + augment_data.shape[0]), axis = 0)\n",
    "    f['Total_Video'][-augment_data.shape[0]:] = augment_data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
