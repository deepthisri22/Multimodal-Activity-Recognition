# Multimodal-Activity-Recognition
Human visual behaviour is a very rich source of information to understand human activities. The
combination of this visual behaviour with scene information could significantly boost the performance
of recognizing activities. We have integrated two different modalities namely visual gaze behaviour and visual scene
information modals using late fusion technique, with a combination of **CNN** and **LSTM** for activity recognition by using long term gaze
information and egocentric view based visual scene information. The objective for this work is taken from the paper [here](https://perceptual.mpi-inf.mpg.de/files/2015/08/Steil_Ubicomp15.pdf).

The dataset used is **Long-term visual behavior dataset** of 10 participants which includes 80 hours of long term
gaze behavior and visual scene information. Details about the dataset can be found [here](https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/human-activity-recognition/discovery-of-everyday-human-activities-from-long-term-visual-behaviour-using-topic-models/)
